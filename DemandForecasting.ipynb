{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemandForecasting.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsbNpGYQpzD_"
      },
      "source": [
        "### Demand forecasting For FMCG Company"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwVHQc-6Hn6S",
        "outputId": "80ae9c5f-1def-4d58-fec7-5c8f75bad1a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!unzip \"/content/mate_labs_demand_forecasting_hiring_challenge-dataset.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/mate_labs_demand_forecasting_hiring_challenge-dataset.zip\n",
            "replace Data/Train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace Data/Train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: Data/Train.csv          \n",
            "  inflating: Data/Test.csv           \n",
            "  inflating: Data/Sample Submission.csv  \n",
            "  inflating: Data/Promotional_Data.csv  \n",
            "  inflating: Data/.~lock.Sample Submission.csv#  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKV-uvexHwOA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from fbprophet import Prophet\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.svm import SVR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IhTEALGqJi1"
      },
      "source": [
        "Reading the csv file and storing it as a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaFPPvSYHylo"
      },
      "source": [
        "train = pd.read_csv(\"/content/Data/Train.csv\")\n",
        "test = pd.read_csv(\"/content/Data/Test.csv\")\n",
        "promo = pd.read_csv(\"/content/Data/Promotional_Data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o19HAthbqT-0"
      },
      "source": [
        "Converting to the datetime format using Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFTiuwjeH01U"
      },
      "source": [
        "train['DATE'] = pd.to_datetime(train['DATE'])\n",
        "test['DATE'] = pd.to_datetime(test['DATE'])\n",
        "promo['DATE'] = pd.to_datetime(promo['DATE'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTvi-ATbJd9A"
      },
      "source": [
        "# Promo csv Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaaQC2-RH2ix"
      },
      "source": [
        "promo['DB Channel'] = promo['DB Channel'].replace(['All'],'0,1,2')\n",
        "promo['DB Channel'] = promo['DB Channel'].replace(['2 only'],'2')\n",
        "promo['DB Channel'] = promo['DB Channel'].replace(['1&0 only'],'0,1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZFwdg17IBsh"
      },
      "source": [
        "def splitDataFrameList(df,target_column,separator):\n",
        "    def splitListToRows(row,row_accumulator,target_column,separator):\n",
        "        split_row = row[target_column].split(separator)\n",
        "        for s in split_row:\n",
        "            new_row = row.to_dict()\n",
        "            new_row[target_column] = s\n",
        "            row_accumulator.append(new_row)\n",
        "    new_rows = []\n",
        "    df.apply(splitListToRows,axis=1,args = (new_rows,target_column,separator))\n",
        "    new_df = pd.DataFrame(new_rows)\n",
        "    return new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZsdBP8gIGg-"
      },
      "source": [
        "promof = splitDataFrameList(promo,'DB Channel', ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8fOgXvqIHLh"
      },
      "source": [
        "promof.rename(columns={'DB Channel':'Channel'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A2ddJ6yMpXq"
      },
      "source": [
        "promof['Channel'] = promof['Channel'].astype(str).astype(int) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hVq9xFVMTTh"
      },
      "source": [
        "def describe_data(df):\n",
        "    print(\"Data Types:\")\n",
        "    print(df.dtypes)\n",
        "    print(\"Rows and Columns:\")\n",
        "    print(df.shape)\n",
        "    print(\"Column Names:\")\n",
        "    print(df.columns)\n",
        "    print(\"Null Values:\")\n",
        "    print(df.apply(lambda x: sum(x.isnull()) / len(df)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxcxnp2gJilJ"
      },
      "source": [
        "# Train csv Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mpZ5socIkHx"
      },
      "source": [
        "train.rename(columns={'Secondary Sales Amount STC':'SSAS','Secondary Sales Amount Invoiced':'SSAI','Secondary Sales Amount Returned':'SSAR','Secondary Sales Quantity Invoiced':'SSQI','Secondary Sales Quantity Returned':'SSQR'}, inplace=True)\n",
        "train.drop(['SSAS','SSAI','SSAR','SSQR'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht1vrwICL6mb"
      },
      "source": [
        "trainf = pd.merge(train, promof, how='left', on=[\"DATE\",'SKU Code','Channel']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpV0f2NuRlE3"
      },
      "source": [
        "trainf[\"Promo\"] = trainf[\"Promo\"].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q948bgfXHOP"
      },
      "source": [
        "trainf[\"year\"] = pd.to_datetime(trainf[\"DATE\"]).dt.year\n",
        "trainf[\"month\"] = pd.to_datetime(trainf[\"DATE\"]).dt.month\n",
        "trainf[\"day\"] = pd.to_datetime(trainf[\"DATE\"]).dt.day\n",
        "trainf.drop([\"DATE\"], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dH8hP4zN0cp"
      },
      "source": [
        "# Test csv Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQSGnO7XIMkl"
      },
      "source": [
        "testf = test.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW_b-_ZBaIUZ",
        "outputId": "aa5f02f3-0033-4649-bd98-d34ba92240a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "describe_data(testf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Types:\n",
            "SKU Code                    int64\n",
            "CFA Code                    int64\n",
            "Channel                     int64\n",
            "Quantity                    int64\n",
            "DATE               datetime64[ns]\n",
            "SKU Combination             int64\n",
            "dtype: object\n",
            "Rows and Columns:\n",
            "(2609, 6)\n",
            "Column Names:\n",
            "Index(['SKU Code', 'CFA Code', 'Channel', 'Quantity', 'DATE',\n",
            "       'SKU Combination'],\n",
            "      dtype='object')\n",
            "Null Values:\n",
            "SKU Code           0.0\n",
            "CFA Code           0.0\n",
            "Channel            0.0\n",
            "Quantity           0.0\n",
            "DATE               0.0\n",
            "SKU Combination    0.0\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sytnTNwvfq4"
      },
      "source": [
        "def dataframe_difference(df1, df2, which=None):\n",
        "    \"\"\"Find rows which are different between two DataFrames.\"\"\"\n",
        "    comparison_df = df1.merge(df2,\n",
        "                              indicator=True,\n",
        "                              how='outer')\n",
        "    if which is None:\n",
        "        diff_df = comparison_df[comparison_df['_merge'] != 'both']\n",
        "    else:\n",
        "        diff_df = comparison_df[comparison_df['_merge'] == which]\n",
        "    diff_df.to_csv('diff.csv',index = False)\n",
        "    return diff_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh8CwkomIg_8"
      },
      "source": [
        "testf = pd.merge(test, promof, how='left', on=[\"DATE\",'SKU Code','Channel']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpd6DS1VOEln"
      },
      "source": [
        "testf[\"Promo\"] = testf[\"Promo\"].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZDwrVN9XFFI"
      },
      "source": [
        "test[\"year\"] = pd.to_datetime(test[\"DATE\"]).dt.year\n",
        "test[\"month\"] = pd.to_datetime(test[\"DATE\"]).dt.month\n",
        "test[\"day\"] = pd.to_datetime(test[\"DATE\"]).dt.day\n",
        "test.drop([\"DATE\"], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hJ-KcPqRulD"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1_yFUJ6RjFJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = trainf.drop('SSQI', axis=1)\n",
        "y = trainf['SSQI']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elj65nh6R1xd"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor  \n",
        "regressor = DecisionTreeRegressor(random_state=0)\n",
        "model = regressor.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMT2ty_kPBcX"
      },
      "source": [
        "from sklearn import linear_model\n",
        "reg = linear_model.BayesianRidge()\n",
        "model = reg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJTcFYnmRDEK"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0, loss='ls').fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWBPAfyuRd8c"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "reg = RandomForestRegressor(random_state=1, n_estimators=10)\n",
        "model = reg.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8aOSVy-SGMk"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "reg1 = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
        "reg2 = RandomForestRegressor(random_state=1, n_estimators=10)\n",
        "reg3 = LinearRegression()\n",
        "ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
        "model = ereg.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l0f9uwbR4YS"
      },
      "source": [
        "y_pred = model.predict(testf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ccrVqEXqeq"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6yJtSLAIopk"
      },
      "source": [
        "output = pd.read_csv(\"/content/Data/Test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6wluSMPXsV8"
      },
      "source": [
        "testf[\"Secondary Sales Quantity Invoiced\"] = y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPHiIsFjdPXj"
      },
      "source": [
        "testf['DATE'] = pd.to_datetime(testf.year*10000+testf.month*100+testf.day,format='%Y%m%d')\n",
        "testf.drop(['year','month','day'],1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KEA1Y9Hcpxt"
      },
      "source": [
        "testf.drop(['SKU Combination','CFA Code','Quantity'],1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y64f1_uj16GE"
      },
      "source": [
        "testf.drop(['Promo'],1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49_vn3yRXxiC"
      },
      "source": [
        "testf.to_csv('testf.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}